# Single-View Background 3D Reconstruction of Cityscapes

<h2 style="text-align:center"><em>-- In-Progress Repo --</em></h2>

## Why this project?

In digital content creation, the challenge of replicating complex
environments with only single images as references is well-known.
This project proposes a novel solution: generating 3D background
models from single images, reducing the information required for
reconstruction. However, due to the inherent limitations of single
images, complete coverage of the desired scene may not be achieved,
resulting in some information loss.

The framework consists of stages including semantic segmentation,
AR-based 3D reconstruction, and transformer mapping for 2D to 3D
object alignment. Each stage contributes to transforming static
images into dynamic, immersive scenes. Through this research, we
aim to advance digital content creation and immersive visualization
technologies by addressing the limitations of single-image
references.[^1]

## Table of Contents
- [Preliminary Works](#preliminary-works)
- [Installation](#installation)
- [Execution](#execution)
- [Method](#method)

## Preliminary Works

## Installation

## Execution

## Method
### Semantic Segmentation
### NeRS Reconstruction
### AR-Based 3D Reconstruction
### R<sup>2</sup>&#8594;R<sup>3</sup> Positioning

[^1]: [NeRS](https://arxiv.org/abs/2110.07604).